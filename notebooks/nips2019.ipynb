{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import arxiv\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nips2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>arxiv_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blind Super-Resolution Kernel Estimation using...</td>\n",
       "      <td>Sefi Bell-Kligler;Assaf Shocher;Michal Irani</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guided Similarity Separation for Image Retrieval</td>\n",
       "      <td>Chundi Liu;Guangwei Yu;Maksims Volkovs;Cheng C...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Average Individual Fairness: Algorithms, Gener...</td>\n",
       "      <td>Saeed Sharifi-Malvajerdi;Michael Kearns;Aaron ...</td>\n",
       "      <td>http://arxiv.org/abs/1905.10607v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greedy InfoMax for Biologically Plausible Self...</td>\n",
       "      <td>Sindy Löwe;Peter O'Connor;Bastiaan Veeling</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dynamics of stochastic gradient descent for tw...</td>\n",
       "      <td>Sebastian Goldt;Madhu Advani;Andrew Saxe;Flore...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Parameter elimination in particle Gibbs sampling</td>\n",
       "      <td>Anna Wigren;Riccardo Sven Risuleo;Lawrence Mur...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nonparametric Density Estimation &amp; Convergence...</td>\n",
       "      <td>Ananya Uppal;Shashank Singh;Barnabas Poczos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>On Robustness of Principal Component Regression</td>\n",
       "      <td>Anish Agarwal;Devavrat Shah;Dennis Shen;Dogyoo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Scalable Bayesian inference of dendritic volta...</td>\n",
       "      <td>Ruoxi Sun; Ian  Kinsella;Scott Linderman;Liam ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optimizing Generalized Rate Metrics through Th...</td>\n",
       "      <td>Harikrishna Narasimhan;Andrew Cotter;Maya Gupta</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Blind Super-Resolution Kernel Estimation using...   \n",
       "1   Guided Similarity Separation for Image Retrieval   \n",
       "2  Average Individual Fairness: Algorithms, Gener...   \n",
       "3  Greedy InfoMax for Biologically Plausible Self...   \n",
       "4  Dynamics of stochastic gradient descent for tw...   \n",
       "5   Parameter elimination in particle Gibbs sampling   \n",
       "6  Nonparametric Density Estimation & Convergence...   \n",
       "7    On Robustness of Principal Component Regression   \n",
       "8  Scalable Bayesian inference of dendritic volta...   \n",
       "9  Optimizing Generalized Rate Metrics through Th...   \n",
       "\n",
       "                                             authors  \\\n",
       "0       Sefi Bell-Kligler;Assaf Shocher;Michal Irani   \n",
       "1  Chundi Liu;Guangwei Yu;Maksims Volkovs;Cheng C...   \n",
       "2  Saeed Sharifi-Malvajerdi;Michael Kearns;Aaron ...   \n",
       "3         Sindy Löwe;Peter O'Connor;Bastiaan Veeling   \n",
       "4  Sebastian Goldt;Madhu Advani;Andrew Saxe;Flore...   \n",
       "5  Anna Wigren;Riccardo Sven Risuleo;Lawrence Mur...   \n",
       "6        Ananya Uppal;Shashank Singh;Barnabas Poczos   \n",
       "7  Anish Agarwal;Devavrat Shah;Dennis Shen;Dogyoo...   \n",
       "8  Ruoxi Sun; Ian  Kinsella;Scott Linderman;Liam ...   \n",
       "9    Harikrishna Narasimhan;Andrew Cotter;Maya Gupta   \n",
       "\n",
       "                            arxiv_id  \n",
       "0                                NaN  \n",
       "1                                NaN  \n",
       "2  http://arxiv.org/abs/1905.10607v1  \n",
       "3                                NaN  \n",
       "4                                NaN  \n",
       "5                                NaN  \n",
       "6                                NaN  \n",
       "7                                NaN  \n",
       "8                                NaN  \n",
       "9                                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10] # not every accepted papers in NIPS 2019 available on arxiv today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 16.29 % of NIPS 2019 papers available on arxiv by 2019-09-13 09:47:12.238688\n"
     ]
    }
   ],
   "source": [
    "print(\"Only {:.2f} % of NIPS 2019 papers available on arxiv by {}\".format(len(df.dropna())/len(df)*100, datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_arxiv(title, authors, k=5):\n",
    "    query = \"title:{} au:{}\".format(title, authors[0].lower().replace(\" \", \"_\"))\n",
    "    results = arxiv.query(query, max_results=k)\n",
    "    found = False\n",
    "    record = None\n",
    "    for result in results:\n",
    "        if title.strip().lower() == result[\"title\"].strip().lower():\n",
    "            if set(authors) == set(result[\"authors\"]):\n",
    "                found = True\n",
    "                record = result\n",
    "                break\n",
    "    return record, found, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " False,\n",
       " [{'id': 'http://arxiv.org/abs/1904.00523v1',\n",
       "   'guidislink': True,\n",
       "   'updated': '2019-04-01T01:14:23Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=1, tm_hour=1, tm_min=14, tm_sec=23, tm_wday=0, tm_yday=91, tm_isdst=0),\n",
       "   'published': '2019-04-01T01:14:23Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=1, tm_hour=1, tm_min=14, tm_sec=23, tm_wday=0, tm_yday=91, tm_isdst=0),\n",
       "   'title': 'Toward Real-World Single Image Super-Resolution: A New Benchmark and A\\n  New Model',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://export.arxiv.org/api/query?search_query=title%3ABlind+Super-Resolution+Kernel+Estimation+using+an+Internal-GAN+au%3Asefi_bell-kligler&id_list=&start=0&max_results=5&sortBy=relevance&sortOrder=descending',\n",
       "    'value': 'Toward Real-World Single Image Super-Resolution: A New Benchmark and A\\n  New Model'},\n",
       "   'summary': 'Most of the existing learning-based single image superresolution (SISR)\\nmethods are trained and evaluated on simulated datasets, where the\\nlow-resolution (LR) images are generated by applying a simple and uniform\\ndegradation (i.e., bicubic downsampling) to their high-resolution (HR)\\ncounterparts. However, the degradations in real-world LR images are far more\\ncomplicated. As a consequence, the SISR models trained on simulated data become\\nless effective when applied to practical scenarios. In this paper, we build a\\nreal-world super-resolution (RealSR) dataset where paired LR-HR images on the\\nsame scene are captured by adjusting the focal length of a digital camera. An\\nimage registration algorithm is developed to progressively align the image\\npairs at different resolutions. Considering that the degradation kernels are\\nnaturally non-uniform in our dataset, we present a Laplacian pyramid based\\nkernel prediction network (LP-KPN), which efficiently learns per-pixel kernels\\nto recover the HR image. Our extensive experiments demonstrate that SISR models\\ntrained on our RealSR dataset deliver better visual quality with sharper edges\\nand finer textures on real-world scenes than those trained on simulated\\ndatasets. Though our RealSR dataset is built by using only two cameras (Canon\\n5D3 and Nikon D810), the trained model generalizes well to other camera devices\\nsuch as Sony a7II and mobile phones.',\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://export.arxiv.org/api/query?search_query=title%3ABlind+Super-Resolution+Kernel+Estimation+using+an+Internal-GAN+au%3Asefi_bell-kligler&id_list=&start=0&max_results=5&sortBy=relevance&sortOrder=descending',\n",
       "    'value': 'Most of the existing learning-based single image superresolution (SISR)\\nmethods are trained and evaluated on simulated datasets, where the\\nlow-resolution (LR) images are generated by applying a simple and uniform\\ndegradation (i.e., bicubic downsampling) to their high-resolution (HR)\\ncounterparts. However, the degradations in real-world LR images are far more\\ncomplicated. As a consequence, the SISR models trained on simulated data become\\nless effective when applied to practical scenarios. In this paper, we build a\\nreal-world super-resolution (RealSR) dataset where paired LR-HR images on the\\nsame scene are captured by adjusting the focal length of a digital camera. An\\nimage registration algorithm is developed to progressively align the image\\npairs at different resolutions. Considering that the degradation kernels are\\nnaturally non-uniform in our dataset, we present a Laplacian pyramid based\\nkernel prediction network (LP-KPN), which efficiently learns per-pixel kernels\\nto recover the HR image. Our extensive experiments demonstrate that SISR models\\ntrained on our RealSR dataset deliver better visual quality with sharper edges\\nand finer textures on real-world scenes than those trained on simulated\\ndatasets. Though our RealSR dataset is built by using only two cameras (Canon\\n5D3 and Nikon D810), the trained model generalizes well to other camera devices\\nsuch as Sony a7II and mobile phones.'},\n",
       "   'authors': ['Jianrui Cai',\n",
       "    'Hui Zeng',\n",
       "    'Hongwei Yong',\n",
       "    'Zisheng Cao',\n",
       "    'Lei Zhang'],\n",
       "   'author_detail': {'name': 'Lei Zhang'},\n",
       "   'author': 'Lei Zhang',\n",
       "   'links': [{'href': 'http://arxiv.org/abs/1904.00523v1',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/1904.00523v1',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'cs.CV',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'cs.CV',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}],\n",
       "   'pdf_url': 'http://arxiv.org/pdf/1904.00523v1',\n",
       "   'affiliation': 'None',\n",
       "   'arxiv_url': 'http://arxiv.org/abs/1904.00523v1',\n",
       "   'arxiv_comment': None,\n",
       "   'journal_reference': None,\n",
       "   'doi': None},\n",
       "  {'id': 'http://arxiv.org/abs/1705.04194v1',\n",
       "   'guidislink': True,\n",
       "   'updated': '2017-05-09T18:45:38Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2017, tm_mon=5, tm_mday=9, tm_hour=18, tm_min=45, tm_sec=38, tm_wday=1, tm_yday=129, tm_isdst=0),\n",
       "   'published': '2017-05-09T18:45:38Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2017, tm_mon=5, tm_mday=9, tm_hour=18, tm_min=45, tm_sec=38, tm_wday=1, tm_yday=129, tm_isdst=0),\n",
       "   'title': 'Influence Function and Robust Variant of Kernel Canonical Correlation\\n  Analysis',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://export.arxiv.org/api/query?search_query=title%3ABlind+Super-Resolution+Kernel+Estimation+using+an+Internal-GAN+au%3Asefi_bell-kligler&id_list=&start=0&max_results=5&sortBy=relevance&sortOrder=descending',\n",
       "    'value': 'Influence Function and Robust Variant of Kernel Canonical Correlation\\n  Analysis'},\n",
       "   'summary': 'Many unsupervised kernel methods rely on the estimation of the kernel\\ncovariance operator (kernel CO) or kernel cross-covariance operator (kernel\\nCCO). Both kernel CO and kernel CCO are sensitive to contaminated data, even\\nwhen bounded positive definite kernels are used. To the best of our knowledge,\\nthere are few well-founded robust kernel methods for statistical unsupervised\\nlearning. In addition, while the influence function (IF) of an estimator can\\ncharacterize its robustness, asymptotic properties and standard error, the IF\\nof a standard kernel canonical correlation analysis (standard kernel CCA) has\\nnot been derived yet. To fill this gap, we first propose a robust kernel\\ncovariance operator (robust kernel CO) and a robust kernel cross-covariance\\noperator (robust kernel CCO) based on a generalized loss function instead of\\nthe quadratic loss function. Second, we derive the IF for robust kernel CCO and\\nstandard kernel CCA. Using the IF of the standard kernel CCA, we can detect\\ninfluential observations from two sets of data. Finally, we propose a method\\nbased on the robust kernel CO and the robust kernel CCO, called {\\\\bf robust\\nkernel CCA}, which is less sensitive to noise than the standard kernel CCA. The\\nintroduced principles can also be applied to many other kernel methods\\ninvolving kernel CO or kernel CCO. Our experiments on synthesized data and\\nimaging genetics analysis demonstrate that the proposed IF of standard kernel\\nCCA can identify outliers. It is also seen that the proposed robust kernel CCA\\nmethod performs better for ideal and contaminated data than the standard kernel\\nCCA.',\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://export.arxiv.org/api/query?search_query=title%3ABlind+Super-Resolution+Kernel+Estimation+using+an+Internal-GAN+au%3Asefi_bell-kligler&id_list=&start=0&max_results=5&sortBy=relevance&sortOrder=descending',\n",
       "    'value': 'Many unsupervised kernel methods rely on the estimation of the kernel\\ncovariance operator (kernel CO) or kernel cross-covariance operator (kernel\\nCCO). Both kernel CO and kernel CCO are sensitive to contaminated data, even\\nwhen bounded positive definite kernels are used. To the best of our knowledge,\\nthere are few well-founded robust kernel methods for statistical unsupervised\\nlearning. In addition, while the influence function (IF) of an estimator can\\ncharacterize its robustness, asymptotic properties and standard error, the IF\\nof a standard kernel canonical correlation analysis (standard kernel CCA) has\\nnot been derived yet. To fill this gap, we first propose a robust kernel\\ncovariance operator (robust kernel CO) and a robust kernel cross-covariance\\noperator (robust kernel CCO) based on a generalized loss function instead of\\nthe quadratic loss function. Second, we derive the IF for robust kernel CCO and\\nstandard kernel CCA. Using the IF of the standard kernel CCA, we can detect\\ninfluential observations from two sets of data. Finally, we propose a method\\nbased on the robust kernel CO and the robust kernel CCO, called {\\\\bf robust\\nkernel CCA}, which is less sensitive to noise than the standard kernel CCA. The\\nintroduced principles can also be applied to many other kernel methods\\ninvolving kernel CO or kernel CCO. Our experiments on synthesized data and\\nimaging genetics analysis demonstrate that the proposed IF of standard kernel\\nCCA can identify outliers. It is also seen that the proposed robust kernel CCA\\nmethod performs better for ideal and contaminated data than the standard kernel\\nCCA.'},\n",
       "   'authors': ['Md. Ashad Alam', 'Kenji Fukumizu', 'Yu-Ping Wang'],\n",
       "   'author_detail': {'name': 'Yu-Ping Wang'},\n",
       "   'author': 'Yu-Ping Wang',\n",
       "   'arxiv_comment': 'arXiv admin note: text overlap with arXiv:1602.05563',\n",
       "   'links': [{'href': 'http://arxiv.org/abs/1705.04194v1',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/1705.04194v1',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'stat.ML',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}],\n",
       "   'pdf_url': 'http://arxiv.org/pdf/1705.04194v1',\n",
       "   'affiliation': 'None',\n",
       "   'arxiv_url': 'http://arxiv.org/abs/1705.04194v1',\n",
       "   'journal_reference': None,\n",
       "   'doi': None},\n",
       "  {'id': 'http://arxiv.org/abs/1904.01926v2',\n",
       "   'guidislink': True,\n",
       "   'updated': '2019-05-08T10:53:44Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2019, tm_mon=5, tm_mday=8, tm_hour=10, tm_min=53, tm_sec=44, tm_wday=2, tm_yday=128, tm_isdst=0),\n",
       "   'published': '2019-04-03T11:36:30Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=4, tm_mday=3, tm_hour=11, tm_min=36, tm_sec=30, tm_wday=2, tm_yday=93, tm_isdst=0),\n",
       "   'title': 'The dual approach to non-negative super-resolution: impact on primal\\n  reconstruction accuracy',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://export.arxiv.org/api/query?search_query=title%3ABlind+Super-Resolution+Kernel+Estimation+using+an+Internal-GAN+au%3Asefi_bell-kligler&id_list=&start=0&max_results=5&sortBy=relevance&sortOrder=descending',\n",
       "    'value': 'The dual approach to non-negative super-resolution: impact on primal\\n  reconstruction accuracy'},\n",
       "   'summary': 'We study the problem of super-resolution, where we recover the locations and\\nweights of non-negative point sources from a few samples of their convolution\\nwith a Gaussian kernel. It has been recently shown that exact recovery is\\npossible by minimising the total variation norm of the measure. An alternative\\npractical approach is to solve its dual. In this paper, we study the stability\\nof solutions with respect to the solutions to the dual problem. In particular,\\nwe establish a relationship between perturbations in the dual variable and the\\nprimal variables around the optimiser. This is achieved by applying a\\nquantitative version of the implicit function theorem in a non-trivial way.',\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://export.arxiv.org/api/query?search_query=title%3ABlind+Super-Resolution+Kernel+Estimation+using+an+Internal-GAN+au%3Asefi_bell-kligler&id_list=&start=0&max_results=5&sortBy=relevance&sortOrder=descending',\n",
       "    'value': 'We study the problem of super-resolution, where we recover the locations and\\nweights of non-negative point sources from a few samples of their convolution\\nwith a Gaussian kernel. It has been recently shown that exact recovery is\\npossible by minimising the total variation norm of the measure. An alternative\\npractical approach is to solve its dual. In this paper, we study the stability\\nof solutions with respect to the solutions to the dual problem. In particular,\\nwe establish a relationship between perturbations in the dual variable and the\\nprimal variables around the optimiser. This is achieved by applying a\\nquantitative version of the implicit function theorem in a non-trivial way.'},\n",
       "   'authors': ['Stephane Chretien', 'Andrew Thompson', 'Bogdan Toader'],\n",
       "   'author_detail': {'name': 'Bogdan Toader'},\n",
       "   'author': 'Bogdan Toader',\n",
       "   'arxiv_comment': '4 pages double column',\n",
       "   'links': [{'href': 'http://arxiv.org/abs/1904.01926v2',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/1904.01926v2',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'math.OC',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'math.OC',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}],\n",
       "   'pdf_url': 'http://arxiv.org/pdf/1904.01926v2',\n",
       "   'affiliation': 'None',\n",
       "   'arxiv_url': 'http://arxiv.org/abs/1904.01926v2',\n",
       "   'journal_reference': None,\n",
       "   'doi': None},\n",
       "  {'id': 'http://arxiv.org/abs/1902.06068v1',\n",
       "   'guidislink': True,\n",
       "   'updated': '2019-02-16T08:39:36Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=16, tm_hour=8, tm_min=39, tm_sec=36, tm_wday=5, tm_yday=47, tm_isdst=0),\n",
       "   'published': '2019-02-16T08:39:36Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=2, tm_mday=16, tm_hour=8, tm_min=39, tm_sec=36, tm_wday=5, tm_yday=47, tm_isdst=0),\n",
       "   'title': 'Deep Learning for Image Super-resolution: A Survey',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://export.arxiv.org/api/query?search_query=title%3ABlind+Super-Resolution+Kernel+Estimation+using+an+Internal-GAN+au%3Asefi_bell-kligler&id_list=&start=0&max_results=5&sortBy=relevance&sortOrder=descending',\n",
       "    'value': 'Deep Learning for Image Super-resolution: A Survey'},\n",
       "   'summary': 'Image Super-Resolution (SR) is an important class of image processing\\ntechniques to enhance the resolution of images and videos in computer vision.\\nRecent years have witnessed remarkable progress of image super-resolution using\\ndeep learning techniques. In this survey, we aim to give a survey on recent\\nadvances of image super-resolution techniques using deep learning approaches in\\na systematic way. In general, we can roughly group the existing studies of SR\\ntechniques into three major categories: supervised SR, unsupervised SR, and\\ndomain-specific SR. In addition, we also cover some other important issues,\\nsuch as publicly available benchmark datasets and performance evaluation\\nmetrics. Finally, we conclude this survey by highlighting several future\\ndirections and open issues which should be further addressed by the community\\nin the future.',\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://export.arxiv.org/api/query?search_query=title%3ABlind+Super-Resolution+Kernel+Estimation+using+an+Internal-GAN+au%3Asefi_bell-kligler&id_list=&start=0&max_results=5&sortBy=relevance&sortOrder=descending',\n",
       "    'value': 'Image Super-Resolution (SR) is an important class of image processing\\ntechniques to enhance the resolution of images and videos in computer vision.\\nRecent years have witnessed remarkable progress of image super-resolution using\\ndeep learning techniques. In this survey, we aim to give a survey on recent\\nadvances of image super-resolution techniques using deep learning approaches in\\na systematic way. In general, we can roughly group the existing studies of SR\\ntechniques into three major categories: supervised SR, unsupervised SR, and\\ndomain-specific SR. In addition, we also cover some other important issues,\\nsuch as publicly available benchmark datasets and performance evaluation\\nmetrics. Finally, we conclude this survey by highlighting several future\\ndirections and open issues which should be further addressed by the community\\nin the future.'},\n",
       "   'authors': ['Zhihao Wang', 'Jian Chen', 'Steven C. H. Hoi'],\n",
       "   'author_detail': {'name': 'Steven C. H. Hoi'},\n",
       "   'author': 'Steven C. H. Hoi',\n",
       "   'links': [{'href': 'http://arxiv.org/abs/1902.06068v1',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/1902.06068v1',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'cs.CV',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'cs.CV',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}],\n",
       "   'pdf_url': 'http://arxiv.org/pdf/1902.06068v1',\n",
       "   'affiliation': 'None',\n",
       "   'arxiv_url': 'http://arxiv.org/abs/1902.06068v1',\n",
       "   'arxiv_comment': None,\n",
       "   'journal_reference': None,\n",
       "   'doi': None},\n",
       "  {'id': 'http://arxiv.org/abs/1405.3379v1',\n",
       "   'guidislink': True,\n",
       "   'updated': '2014-05-14T06:50:08Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2014, tm_mon=5, tm_mday=14, tm_hour=6, tm_min=50, tm_sec=8, tm_wday=2, tm_yday=134, tm_isdst=0),\n",
       "   'published': '2014-05-14T06:50:08Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2014, tm_mon=5, tm_mday=14, tm_hour=6, tm_min=50, tm_sec=8, tm_wday=2, tm_yday=134, tm_isdst=0),\n",
       "   'title': 'Learning rates for the risk of kernel based quantile regression\\n  estimators in additive models',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://export.arxiv.org/api/query?search_query=title%3ABlind+Super-Resolution+Kernel+Estimation+using+an+Internal-GAN+au%3Asefi_bell-kligler&id_list=&start=0&max_results=5&sortBy=relevance&sortOrder=descending',\n",
       "    'value': 'Learning rates for the risk of kernel based quantile regression\\n  estimators in additive models'},\n",
       "   'summary': 'Additive models play an important role in semiparametric statistics. This\\npaper gives learning rates for regularized kernel based methods for additive\\nmodels. These learning rates compare favourably in particular in high\\ndimensions to recent results on optimal learning rates for purely nonparametric\\nregularized kernel based quantile regression using the Gaussian radial basis\\nfunction kernel, provided the assumption of an additive model is valid.\\nAdditionally, a concrete example is presented to show that a Gaussian function\\ndepending only on one variable lies in a reproducing kernel Hilbert space\\ngenerated by an additive Gaussian kernel, but does not belong to the\\nreproducing kernel Hilbert space generated by the multivariate Gaussian kernel\\nof the same variance.',\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://export.arxiv.org/api/query?search_query=title%3ABlind+Super-Resolution+Kernel+Estimation+using+an+Internal-GAN+au%3Asefi_bell-kligler&id_list=&start=0&max_results=5&sortBy=relevance&sortOrder=descending',\n",
       "    'value': 'Additive models play an important role in semiparametric statistics. This\\npaper gives learning rates for regularized kernel based methods for additive\\nmodels. These learning rates compare favourably in particular in high\\ndimensions to recent results on optimal learning rates for purely nonparametric\\nregularized kernel based quantile regression using the Gaussian radial basis\\nfunction kernel, provided the assumption of an additive model is valid.\\nAdditionally, a concrete example is presented to show that a Gaussian function\\ndepending only on one variable lies in a reproducing kernel Hilbert space\\ngenerated by an additive Gaussian kernel, but does not belong to the\\nreproducing kernel Hilbert space generated by the multivariate Gaussian kernel\\nof the same variance.'},\n",
       "   'authors': ['Andreas Christmann', 'Ding-Xuan Zhou'],\n",
       "   'author_detail': {'name': 'Ding-Xuan Zhou'},\n",
       "   'author': 'Ding-Xuan Zhou',\n",
       "   'arxiv_comment': '35 pages, 2 figures',\n",
       "   'links': [{'href': 'http://arxiv.org/abs/1405.3379v1',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/1405.3379v1',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'stat.ML',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'stat.ML',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}],\n",
       "   'pdf_url': 'http://arxiv.org/pdf/1405.3379v1',\n",
       "   'affiliation': 'None',\n",
       "   'arxiv_url': 'http://arxiv.org/abs/1405.3379v1',\n",
       "   'journal_reference': None,\n",
       "   'doi': None}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_arxiv(title=df.loc[0][\"title\"], authors=df.loc[0][\"authors\"].split(\";\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1430/1430 [19:52<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(df))):\n",
    "    if not isinstance(df.loc[i][\"arxiv_id\"], str):\n",
    "        title = df.loc[i][\"title\"]\n",
    "        authors = df.loc[i][\"authors\"].split(\";\")\n",
    "        record, results, found = retrieve_arxiv(title, authors)\n",
    "        if record is not None and found:\n",
    "            df.loc[i][\"arxiv_id\"] = record[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 16.50 % of NIPS 2019 papers available on arxiv by 2019-09-13 10:07:19.064846\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"nips2019.csv\", index=False) # a little bit increased\n",
    "print(\"Only {:.2f} % of NIPS 2019 papers available on arxiv by {}\".format(len(df.dropna())/len(df)*100, datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
